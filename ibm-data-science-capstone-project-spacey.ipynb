{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview","metadata":{}},{"cell_type":"markdown","source":"This project is part of the [IBM Data Science Certification program](https://www.coursera.org/learn/applied-data-science-capstone/home/welcome)\n\nThe commercial space age is here; several companies such as Virgin Galactic, Blue Origin, and SpaceX are making space travel affordable for everyone. Among all of them, SpaceX perhaps stands out as the most successful. One reason behind SpaceX's success is that the rocket launches are relatively inexpensive thanks to the reusability of the first stage--which is the most expensive part of a rocket launcher that carries most of the work. Therefore, if we can determine if the first stage will land, we can determine the cost of a launch. In this project, our job will be to determine the price of each launch which depends on whether the first stage would land successfully to be reused. Using machine learning models and public data on Falcon 9, we will predict if SpaceX will reuse the first stage.","metadata":{}},{"cell_type":"markdown","source":"### Table of Contents\n* [Data Wrangling](#data-wrangling)\n   * [Import Data](#data-import)\n   * [Dealing with missing values](#missing-data)\n* [EDA](#eda)\n   * [Extract Target Variable](#eda-target)\n   * [Features Selection](#fs)\n       * [Discard Obsolete Variables](#fs-drop-columns)\n       * [Categorical Variables](#fs-categorical)\n       * [Boolean Variables](#fs-boolean)\n       * [Numeric Variables](#fs-numeric)\n   * [Build Features Set](#fs-build-dataset)\n* [Machine Learning Predictions](#ml-predictions)\n   * [Decision Tree](#ml-decision-tree)\n   * [Results](#ml-results)\n    ","metadata":{}},{"cell_type":"markdown","source":"# Data Wrangling <a class=\"anchor\"  id=\"data-wrangling\"></a>","metadata":{}},{"cell_type":"code","source":"!python -m pip install pickle5","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:30.144312Z","iopub.execute_input":"2021-10-19T15:45:30.144615Z","iopub.status.idle":"2021-10-19T15:45:36.701125Z","shell.execute_reply.started":"2021-10-19T15:45:30.144585Z","shell.execute_reply":"2021-10-19T15:45:36.700236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.703657Z","iopub.execute_input":"2021-10-19T15:45:36.704293Z","iopub.status.idle":"2021-10-19T15:45:36.712711Z","shell.execute_reply.started":"2021-10-19T15:45:36.704249Z","shell.execute_reply":"2021-10-19T15:45:36.71184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Data <a class=\"anchor\"  id=\"data-import\"></a>\nThe piece of code used to retrieve the Falcon 9 data was taken from this [notebook]('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_1_L2/jupyter-labs-spacex-data-collection-api.ipynb') which contains an API designed for this puspose and privided with the project assignment.","metadata":{}},{"cell_type":"code","source":"import pickle5 as pickle\n\nwith open(\"../input/spacex-falcon9-launch-pickle/falcon9_data.pkl\", \"rb\") as fh:\n    data = pickle.load(fh)\n    falcon9_data = data\n    falcon9_data.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.714209Z","iopub.execute_input":"2021-10-19T15:45:36.71445Z","iopub.status.idle":"2021-10-19T15:45:36.732353Z","shell.execute_reply.started":"2021-10-19T15:45:36.714423Z","shell.execute_reply":"2021-10-19T15:45:36.73157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"falcon9_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.734275Z","iopub.execute_input":"2021-10-19T15:45:36.734516Z","iopub.status.idle":"2021-10-19T15:45:36.759958Z","shell.execute_reply.started":"2021-10-19T15:45:36.734491Z","shell.execute_reply":"2021-10-19T15:45:36.759326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dealing with missing values <a class=\"anchor\"  id=\"missing-data\"></a>\nWe can see below that some of the rows are missing values in our dataset. As our dataset only contains 119 observations, we will avoid removing rows containing null data but rather fill the missing data using different techniques.","metadata":{}},{"cell_type":"code","source":"falcon9_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.760813Z","iopub.execute_input":"2021-10-19T15:45:36.761431Z","iopub.status.idle":"2021-10-19T15:45:36.770403Z","shell.execute_reply.started":"2021-10-19T15:45:36.761398Z","shell.execute_reply":"2021-10-19T15:45:36.769582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We deal with the missing values in `PayloadMass` by replacing the null values with the median.\n\nSimilarily, we deal with the missing values in `Orbit`by replacing the null values with the mode.","metadata":{}},{"cell_type":"code","source":"# Fill missing PayloadMass with median\nfalcon9_data['PayloadMass'].fillna(falcon9_data['PayloadMass'].median(), inplace=True)\n\n# Fill missing PayloadMass with median\nfalcon9_data['Orbit'].fillna(falcon9_data['Orbit'].mode().values[0], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.771478Z","iopub.execute_input":"2021-10-19T15:45:36.773299Z","iopub.status.idle":"2021-10-19T15:45:36.780263Z","shell.execute_reply.started":"2021-10-19T15:45:36.773261Z","shell.execute_reply":"2021-10-19T15:45:36.779551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When it comes to `Flights`, we can retrieve the number of flights a particular rocket has done by using the `Serial` variable to count the number of flights of the corresponding rocket has made after the current observed `Date`. If there were no other flights of a rocket with the same serial number after the current observed date then `Flights` will be set to `1`.","metadata":{}},{"cell_type":"code","source":"# Fill missing Flights\nfalcon9_data.loc[falcon9_data['Flights'].isnull(), 'Flights'] = falcon9_data[falcon9_data['Flights'].isnull()]\\\n    .apply(lambda x: 1 + falcon9_data.loc[(falcon9_data['Serial'] == x['Serial']) & (falcon9_data['Date'] > x['Date'])].shape[0], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.781215Z","iopub.execute_input":"2021-10-19T15:45:36.781828Z","iopub.status.idle":"2021-10-19T15:45:36.795049Z","shell.execute_reply.started":"2021-10-19T15:45:36.781792Z","shell.execute_reply":"2021-10-19T15:45:36.794396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Certain variables such as `GridFins`, `Reused`, and `Legs` are of type boolean. We can then assume the missing values to be `False`. Similarily, we can assume the missing values in `ReusedCount` to be `0` when the corresponding `Reused` variable is set to `False` or also missing.","metadata":{}},{"cell_type":"code","source":"# Fill missing GridFins, Reused, and Legs with False\nfalcon9_data['GridFins'].fillna(False, inplace=True)\nfalcon9_data['Reused'].fillna(False, inplace=True)\nfalcon9_data['Legs'].fillna(False, inplace=True)\n\n# Fill missing ReusedCount with 0\nfalcon9_data['ReusedCount'].fillna(0, inplace=True)\nfalcon9_data['Block'].fillna(0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.796519Z","iopub.execute_input":"2021-10-19T15:45:36.797033Z","iopub.status.idle":"2021-10-19T15:45:36.806026Z","shell.execute_reply.started":"2021-10-19T15:45:36.796985Z","shell.execute_reply":"2021-10-19T15:45:36.805108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"At last, `Serial` contains the serial number of the rockets. If the `Serial` is not provided, we could set its missing values to `unknown`.","metadata":{}},{"cell_type":"code","source":"# Fill missing Serial with 'unknown'\nfalcon9_data['Serial'].fillna('Unknown', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.807119Z","iopub.execute_input":"2021-10-19T15:45:36.807342Z","iopub.status.idle":"2021-10-19T15:45:36.819382Z","shell.execute_reply.started":"2021-10-19T15:45:36.807317Z","shell.execute_reply":"2021-10-19T15:45:36.818744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"At this point, only `LandingPad` contains missing values. However, the fact the missing values of this particular variable are meaningful as they imply there was not landing pad used during the launch.\n\nBefore starting our EDA, we rename the values of the column `LandingPad` to make them more readable. We also replace the missing values with `NoLandingPad`.","metadata":{}},{"cell_type":"code","source":"padno = 0\nfor padid in falcon9_data[\"LandingPad\"].unique():\n    if padid is not None:\n        falcon9_data[\"LandingPad\"].replace(padid, f\"LandingPad_{padno}\", inplace=True)\n    else:\n        falcon9_data[\"LandingPad\"].fillna(\"NoLandingPad\", inplace=True)\n    padno += 1\n\ndel padno","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.82183Z","iopub.execute_input":"2021-10-19T15:45:36.822439Z","iopub.status.idle":"2021-10-19T15:45:36.834327Z","shell.execute_reply.started":"2021-10-19T15:45:36.822411Z","shell.execute_reply":"2021-10-19T15:45:36.833634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fixing data types\nWe make sure each feature has the right data type","metadata":{}},{"cell_type":"code","source":"falcon9_data[\"Date\"] = pd.to_datetime(falcon9_data[\"Date\"])\nfalcon9_data[\"Flights\"] = falcon9_data[\"Flights\"].astype(int)\nfalcon9_data[\"GridFins\"] = falcon9_data[\"GridFins\"].astype(bool)\nfalcon9_data[\"Reused\"] = falcon9_data[\"Reused\"].astype(bool)\nfalcon9_data[\"Legs\"] = falcon9_data[\"Legs\"].astype(bool)\nfalcon9_data[\"Block\"] = falcon9_data[\"Block\"].astype(int)\nfalcon9_data[\"ReusedCount\"] = falcon9_data[\"ReusedCount\"].astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.83536Z","iopub.execute_input":"2021-10-19T15:45:36.836033Z","iopub.status.idle":"2021-10-19T15:45:36.849025Z","shell.execute_reply.started":"2021-10-19T15:45:36.836005Z","shell.execute_reply":"2021-10-19T15:45:36.84809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save cleaned data\nAt this stage, our data is clean. The numeric values (including `Date`) appears to be in the proper range and looking at the unique values of the categorical values, we did not identify any typos.\n\nWe can then safely save the cleaned dataset to the disk.","metadata":{}},{"cell_type":"code","source":"# falcon9_data.to_pickle(\"falcon9_data_clean_v1.pkl\")","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.851773Z","iopub.execute_input":"2021-10-19T15:45:36.852229Z","iopub.status.idle":"2021-10-19T15:45:36.859572Z","shell.execute_reply.started":"2021-10-19T15:45:36.852201Z","shell.execute_reply":"2021-10-19T15:45:36.858873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis & Features Selection <a class=\"anchor\"  id=\"eda\"></a>","metadata":{}},{"cell_type":"code","source":"# Make a copy\ndf = falcon9_data.copy()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.860464Z","iopub.execute_input":"2021-10-19T15:45:36.861017Z","iopub.status.idle":"2021-10-19T15:45:36.874094Z","shell.execute_reply.started":"2021-10-19T15:45:36.860986Z","shell.execute_reply":"2021-10-19T15:45:36.873026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.875713Z","iopub.execute_input":"2021-10-19T15:45:36.875992Z","iopub.status.idle":"2021-10-19T15:45:36.889491Z","shell.execute_reply.started":"2021-10-19T15:45:36.875952Z","shell.execute_reply":"2021-10-19T15:45:36.88864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Process Target Variable <a class=\"anchor\"  id=\"eda-target\"></a>","metadata":{}},{"cell_type":"markdown","source":"The variable `Outcome` is composed of two parts. First, we have a boolean value (True or False) or 'None' that indicates if the launch was successful or not. The second part indicates where the first stage landed. For example `True Ocean` means the mission outcome was successfully  landed to a specific region of the ocean while <code>False Ocean</code> means the mission outcome was unsuccessfully landed to a specific region of the ocean. `None ASDS` and `None None` these represent a failure to land.\n\nWe can then split `Outcome` into two columns `LandingOutcome` and `landingRegion`. We will be using the `landingOutcome` column as our target.","metadata":{}},{"cell_type":"code","source":"df[[\"LandingOutcome\", \"LandingRegion\"]] = df[\"Outcome\"].str.split(\" \", 1, expand=True)\n\n# We fill the null values in LandingPlace by 'Failed' signaling that the launch was a failure.\n# df[\"LandingRegion\"].replace(\"None\", \"Failed\", inplace=True)\n\n# Replace null values by False in LandingOutcome\ndf[\"LandingOutcome\"].replace('None', 0, inplace=True)\ndf[\"LandingOutcome\"].replace('False', 0, inplace=True)\ndf[\"LandingOutcome\"].replace('True', 1, inplace=True)\n\n# While were are at it, we can set the successful launch to 1 and the unsuccessful to 0 from the boolean values\ndf = df.astype({\"LandingOutcome\": int})","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.890809Z","iopub.execute_input":"2021-10-19T15:45:36.891725Z","iopub.status.idle":"2021-10-19T15:45:36.909903Z","shell.execute_reply.started":"2021-10-19T15:45:36.891694Z","shell.execute_reply":"2021-10-19T15:45:36.908863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop old Outcome column\ndf.drop(columns=[\"Outcome\"], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.91114Z","iopub.execute_input":"2021-10-19T15:45:36.911371Z","iopub.status.idle":"2021-10-19T15:45:36.917444Z","shell.execute_reply.started":"2021-10-19T15:45:36.911337Z","shell.execute_reply":"2021-10-19T15:45:36.916664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"round(100 * df[\"LandingOutcome\"].value_counts() / df.shape[0], 2)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.918756Z","iopub.execute_input":"2021-10-19T15:45:36.919095Z","iopub.status.idle":"2021-10-19T15:45:36.933019Z","shell.execute_reply.started":"2021-10-19T15:45:36.91906Z","shell.execute_reply":"2021-10-19T15:45:36.932405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our two classes `0` (Failure) and `1` (Success) are considerably imbalanced. Out of every rocket launch in the dataset, 73.11% were successful whereas 26.89% were unsuccsessful.","metadata":{}},{"cell_type":"markdown","source":"## Features Selection <a class=\"anchor\"  id=\"fs\"></a>","metadata":{}},{"cell_type":"markdown","source":"### Helper functions","metadata":{}},{"cell_type":"code","source":"from scipy.stats import chi2_contingency\nfrom scipy.stats import pearsonr","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.934063Z","iopub.execute_input":"2021-10-19T15:45:36.934278Z","iopub.status.idle":"2021-10-19T15:45:36.943939Z","shell.execute_reply.started":"2021-10-19T15:45:36.934254Z","shell.execute_reply":"2021-10-19T15:45:36.943112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply Chi Squared test then plot the p-values on a heatmap\ndef plot_chisquare_heatmap(df, target, column_names, figsize=(8,6)):\n    column_names.append(target)\n    n_cols = len(column_names)\n    chisq_df = pd.DataFrame(np.zeros((n_cols,n_cols)), columns=column_names, index=column_names)\n    i = 0\n    j = 0\n    \n    for icol in column_names:\n        for jcol in column_names:\n            # Build contigency table\n            contigency_tab = pd.crosstab(df[icol], df[jcol])\n            \n            # Get p-value and other stats\n            c, p, dof, expected = chi2_contingency(contigency_tab)\n            \n            # We round very low p-values to 0 and add the p-values to the chisq_matrix\n            chisq_df.iloc[i,j] = round(p, 5)\n            \n            # A condition to use Chi Square is that the expected frequencies should be at \n            # least 5 for the majority (80%) of the cells\n            \n            # Get % of cells with frequency of at least 5\n            expected_percent = 100 * expected[expected >= 5].size / expected.size\n            \n            #if icol == jcol:\n            #    chisq_df.iloc[i,j] = 0.0\n            \n            # If the expected frequency is less than 5 for the (20%), we ignore the p-value\n            # between the two variables. We will then keep the two variables.\n            # We set the p-value to 2 in order to better visualize this case\n            if expected_percent < 20:\n                chisq_df.iloc[i,j] = 2\n            else:\n                chisq_df.iloc[i,j] = round(p, 5)\n            \n            j += 1\n            \n        i += 1\n        j = 0\n    \n    _, ax = plt.subplots(figsize=figsize)\n    sns.heatmap(chisq_df, annot=True, ax=ax)\n    #ax.set_xticklabels(labels=cols, rotation=90)\n    #ax.set_yticklabels(labels=cols, rotation=0)\n    ax.set_title(\"Chi Squared p-values\", fontsize=14)\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.945324Z","iopub.execute_input":"2021-10-19T15:45:36.945645Z","iopub.status.idle":"2021-10-19T15:45:36.95806Z","shell.execute_reply.started":"2021-10-19T15:45:36.945616Z","shell.execute_reply":"2021-10-19T15:45:36.957099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute the correlation between variables and the statistical significance of that correlation\n# then plot the correlation coefficient and p-values on a heatmap\ndef plot_corr_pvalue(df, column_names, figsize=(11, 4)):\n    ncols = len(column_names)\n    corr_matrix = pd.DataFrame(np.zeros((ncols, ncols)), columns=column_names, index=column_names)\n    pvalue_matrix = pd.DataFrame(np.zeros((ncols, ncols)), columns=column_names, index=column_names)\n    i = 0\n    j = 0\n    \n    for icol in column_names:\n        for jcol in column_names:\n            # Compute correlation coefficient and p-value\n            corr, p = pearsonr(df[icol], df[jcol])\n            \n            corr_matrix.iloc[i,j] = round(corr, 5)\n            \n            # We round very low p-values to 0\n            pvalue_matrix.iloc[i,j] = round(p, 5)\n            j += 1\n            \n        j = 0\n        i += 1\n    \n    _, ax = plt.subplots(figsize=figsize, ncols=2, nrows=1)\n    # Plot correlation matrix\n    sns.heatmap(corr_matrix, annot=True, ax=ax[0])\n    ax[0].set_title(\"Correlation Matrix\", fontsize=14)\n    ax[0].set_xticklabels(column_names, rotation=90)\n    ax[0].set_yticklabels(column_names, rotation=0)\n    \n    # Plot p-values matrix\n    sns.heatmap(pvalue_matrix, annot=True, ax=ax[1])\n    ax[1].set_title(\"p-values Matrix\", fontsize=14)\n    ax[1].set_xticklabels(column_names, rotation=90)\n    ax[1].set_yticklabels(column_names, rotation=0)\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.959471Z","iopub.execute_input":"2021-10-19T15:45:36.959854Z","iopub.status.idle":"2021-10-19T15:45:36.974488Z","shell.execute_reply.started":"2021-10-19T15:45:36.959825Z","shell.execute_reply":"2021-10-19T15:45:36.973737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_barchart(df, columns, figsize=(18, 4)):\n    ncols = len(columns)\n    _, axes = plt.subplots(figsize=figsize, ncols=ncols, nrows=1)\n    for i in range(len(columns)):\n        axes[i].set_title(f\"Landing Success Rate\", fontsize=14)\n        sns.barplot(x=df.groupby(columns[i]).apply(lambda x: str(x.name)),\n                    y=\"LandingOutcome\",\n                    data=round(100 * df.groupby(columns[i]).mean(), 2), ax=axes[i])\n        axes[i].set_xlabel(columns[i])\n        axes[i].set_ylabel(\"Success Rate (%)\")\n        \n        if columns[i] == \"LandingPad\":\n            axes[i].set_xticklabels(axes[i].xaxis.get_ticklabels(), rotation=90)\n        \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.97561Z","iopub.execute_input":"2021-10-19T15:45:36.975993Z","iopub.status.idle":"2021-10-19T15:45:36.990049Z","shell.execute_reply.started":"2021-10-19T15:45:36.975966Z","shell.execute_reply":"2021-10-19T15:45:36.98911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_kde(df, column_names, target, ncols=2):\n    nrows = int(np.ceil(len(column_names) / ncols))\n    _, ax = plt.subplots(figsize=(5.5 * ncols * 1.1, 3 * nrows * 1.3), ncols=ncols, nrows=nrows)\n    for i in range(len(column_names)):\n        sns.kdeplot(data=df, x=column_names[i], hue=target, alpha=0.9, ax=ax[i//ncols][i%ncols])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:36.991213Z","iopub.execute_input":"2021-10-19T15:45:36.991456Z","iopub.status.idle":"2021-10-19T15:45:37.006919Z","shell.execute_reply.started":"2021-10-19T15:45:36.991428Z","shell.execute_reply":"2021-10-19T15:45:37.005935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create New Variables and Drop Obsolete/Redundant Variables <a class=\"anchor\"  id=\"fs-drop-columns\"></a>\nSome of the variables of our datasets are redundant or not useful. First, `FlightNumber` is used as an ID for each of the flights. Therefore, it does not hold much values for our classification problem. Similarily, `BoosterVersion` only has one single possible values (Falcon 9). At last, `Longitude` and `Latitude` are coordonates of each `LauchSite`. The pair of geo coordinates could be substituted by the corresponding `LaunchSite`.","metadata":{}},{"cell_type":"markdown","source":"From the `Date` column, we can extract the `Year`.","metadata":{}},{"cell_type":"code","source":"df[\"Year\"] = df[\"Date\"].dt.year","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:37.008123Z","iopub.execute_input":"2021-10-19T15:45:37.008723Z","iopub.status.idle":"2021-10-19T15:45:37.022328Z","shell.execute_reply.started":"2021-10-19T15:45:37.00869Z","shell.execute_reply":"2021-10-19T15:45:37.021355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns=[\"Date\", \"FlightNumber\", \"BoosterVersion\", \"Longitude\", \"Latitude\"], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:37.023849Z","iopub.execute_input":"2021-10-19T15:45:37.024726Z","iopub.status.idle":"2021-10-19T15:45:37.033593Z","shell.execute_reply.started":"2021-10-19T15:45:37.024677Z","shell.execute_reply":"2021-10-19T15:45:37.032917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorical Variables <a class=\"anchor\"  id=\"fs-categorical\"></a>","metadata":{}},{"cell_type":"markdown","source":"We start with the categorical features. As we are dealing with a classification problem with multiple categorical features, it appropriate to use the Chi Square method for feature selection. \n\nWe use the function `plot_chisquare_heatmap` to produce a heatmap of p-values obtain by applying Chi Square on our categorical features and target. A p-value lower than 0.05 in this case indicate that there exists a relationship between two variables. Otherwise, the two variables are considered independent.\n\nOne of the condition to use Chi Squared is that the expected frequencies should be at least 5 for the majority (80%) of the cells. When this condition is not satisfied, `plot_chisquare_heatmap` sets the p-value to `2` thus indicating that the two variables could be used.","metadata":{}},{"cell_type":"code","source":"# Group categorical features in a list\ncategorical_cols = [\"Orbit\", \"LaunchSite\", \"LandingPad\", \"Serial\", \"LandingRegion\"]\n\n# Plot heatmap of p-values\nplot_chisquare_heatmap(df, column_names=categorical_cols, target=\"LandingOutcome\")","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:37.036448Z","iopub.execute_input":"2021-10-19T15:45:37.036765Z","iopub.status.idle":"2021-10-19T15:45:37.866222Z","shell.execute_reply.started":"2021-10-19T15:45:37.036735Z","shell.execute_reply":"2021-10-19T15:45:37.864831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above heatmap we see that `Serial` do not satisfy the condition of a Chi Square test. Moreover, `Serial` is a used to uniquely identify a given rocket. As our goal is to predict the success of any rocket launch based on certain features, this information could be irrelevant. We can then remove those three columns from our features set.\n\nNext, `Orbit` and `LaunchSite` have a p-value of 0.17 and 0.21 respectively when evaluated against the target. These two variables are also not independent from each other as shown in the Chi Squared p-values table.\n\n`LauchSite` also has a relationship with `LandingPad`. As the later has a stronger relationship with the target variable, we can drop `LaunchSite` from our features set.\n\nThere appears to be a strong relationship between `LandingPad` and `LandingRegion`. As the two variables are not independent, we could drop one of them. \n\nLet's visualize how the launches success rate varies with different values of `LandingPad`, `LandingRegion`, and `Orbit`.","metadata":{}},{"cell_type":"code","source":"plot_barchart(df, columns=[\"Orbit\", \"LandingPad\", \"LandingRegion\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:37.867344Z","iopub.execute_input":"2021-10-19T15:45:37.867571Z","iopub.status.idle":"2021-10-19T15:45:38.434726Z","shell.execute_reply.started":"2021-10-19T15:45:37.867535Z","shell.execute_reply":"2021-10-19T15:45:38.434055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The bar charts above show some variations in the success rate of rocket landings with different variables. \n\nThe lauches have a higher success rate when launched in certain `Orbit` than others. For example, ES-L1, GEO, HEO, and SSO have a 100% success rate while SO is at 0%.\n\nSimilarily to `Orbit`, the different `LandingRegion` also lead to different success rates. RTLS has the highest success rate while landing on the Ocean is less efficient.\n\nOn the other hand, there does  not appears to be much difference in the success rate of different `LandingPad`. Beside using `LandingPad_1` and no landing pad, all the other possibilities lead to similar success rates.","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df[\"LandingPad\"], df[\"LandingRegion\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:38.435716Z","iopub.execute_input":"2021-10-19T15:45:38.436264Z","iopub.status.idle":"2021-10-19T15:45:38.455288Z","shell.execute_reply.started":"2021-10-19T15:45:38.436235Z","shell.execute_reply":"2021-10-19T15:45:38.454733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As noted earlier in the Chi Squared p-values matrix, there seem to be a strong relationship between `LandingPad` and `LandingRegion`. The contigency table above shows that each landing pad is associated with only one single `LandingRegion`. Not using a landing pas (NoLandingPad) either lead to a failure to launch or a landing on the ocean. Considering this information additional information, we can discard `LandingPad` from the features set and only consider `LandingRegion`.","metadata":{}},{"cell_type":"code","source":"df.drop(columns=[\"Serial\", \"LaunchSite\", \"LandingPad\"], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:38.458817Z","iopub.execute_input":"2021-10-19T15:45:38.459299Z","iopub.status.idle":"2021-10-19T15:45:38.46374Z","shell.execute_reply.started":"2021-10-19T15:45:38.459269Z","shell.execute_reply":"2021-10-19T15:45:38.463109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Boolean Variables <a class=\"anchor\"  id=\"fs-boolean\"></a>\nWe have in total 3 variables of type Boolean: `GridFins`, `Reused`, and `Legs`. We can visualize the relationship between these variables and the target using a bar chart.","metadata":{}},{"cell_type":"code","source":"boolean_cols = [\"GridFins\", \"Legs\", \"Reused\"]\n# Plot correlation and p-values matrices\nplot_corr_pvalue(df, boolean_cols + [\"LandingOutcome\"], figsize=(14.5, 5))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:38.465015Z","iopub.execute_input":"2021-10-19T15:45:38.465421Z","iopub.status.idle":"2021-10-19T15:45:39.136208Z","shell.execute_reply.started":"2021-10-19T15:45:38.465394Z","shell.execute_reply":"2021-10-19T15:45:39.135299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we can observe that all three of our boolean variables have a relationship with `LandingOutcome`. We use a correlation matrix have a better sense on the strengh of the relationships.\n\nThe correlation matrix above shows that the variables `GridFins` and `Legs` are highly correlated (91%). As `Legs` shows the largest difference in the success rate and strongest correlation to `LandingOutcome`, we will ignore `GridFins`.","metadata":{}},{"cell_type":"code","source":"df.drop(columns=[\"GridFins\"], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:39.137356Z","iopub.execute_input":"2021-10-19T15:45:39.137623Z","iopub.status.idle":"2021-10-19T15:45:39.142767Z","shell.execute_reply.started":"2021-10-19T15:45:39.137592Z","shell.execute_reply":"2021-10-19T15:45:39.142142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The variable `Reused` has a weak correlation with the target. However, we can notice that `Reused` and `ReusedCount` are linked. As `ReusedCount` provides more information--and not just `True` or `False`--it could be a stronger feature. ","metadata":{}},{"cell_type":"code","source":"plot_barchart(df, columns=[\"Reused\", \"ReusedCount\"], figsize=(12, 4))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:39.143628Z","iopub.execute_input":"2021-10-19T15:45:39.144252Z","iopub.status.idle":"2021-10-19T15:45:39.507176Z","shell.execute_reply.started":"2021-10-19T15:45:39.144219Z","shell.execute_reply":"2021-10-19T15:45:39.506084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The bar plot above shows the success rate of the first stage landing based on how many time it has been reused. The difference in the success rate does not appear to be significant especially when we consider that when a rocket fail launch or land, it it destroyed. The first stage is only reusable until it is destroy. Our goal is to predict if the outcome of le landing will be positive thus indicating that the first stage could be reused in the futur. Therefore, we can drop both `Reused` and `ReusedCount` from the features set.","metadata":{}},{"cell_type":"code","source":"df.drop(columns=[\"Reused\", \"ReusedCount\"], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:39.508604Z","iopub.execute_input":"2021-10-19T15:45:39.5095Z","iopub.status.idle":"2021-10-19T15:45:39.51557Z","shell.execute_reply.started":"2021-10-19T15:45:39.509455Z","shell.execute_reply":"2021-10-19T15:45:39.514648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Numeric Variables <a class=\"anchor\"  id=\"fs-numeric\"></a>\nWe are left with 4 numeric variables to consider: `PayloadMass`, `Flights`, `Block`, and `ReusedCount`.","metadata":{}},{"cell_type":"code","source":"numeric_cols = [\"Year\", \"PayloadMass\", \"Flights\", \"Block\"]\n# Plot correlation and p-values matrices\nplot_corr_pvalue(df, numeric_cols + [\"LandingOutcome\"], figsize=(16.5, 5.2))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:39.516665Z","iopub.execute_input":"2021-10-19T15:45:39.517231Z","iopub.status.idle":"2021-10-19T15:45:40.33066Z","shell.execute_reply.started":"2021-10-19T15:45:39.517198Z","shell.execute_reply":"2021-10-19T15:45:40.32967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_kde(df, numeric_cols, target=\"LandingOutcome\", ncols=2)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:40.331947Z","iopub.execute_input":"2021-10-19T15:45:40.332199Z","iopub.status.idle":"2021-10-19T15:45:41.459853Z","shell.execute_reply.started":"2021-10-19T15:45:40.332171Z","shell.execute_reply":"2021-10-19T15:45:41.458927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`Year` and `Block` are correlated to each other with a coefficient of 0.85. This suggests a colinearity between the two variables, thus we should drop one.\n\nLooking at the density plot above, we can see that the success rate of the first stage landings grows by the years. However, the year alone as a value would not have much impact on the success rate. We can assume that the higher success rate in the most recent years is due not by the year itself but rather some newer techniques or features added to the rockets and/or landing procedures. For this reason, `Block` would be a better feature to use in our classification problem.\n\n`PayloadMass` and `Flights` have the lowest correlation coefficients thus suggesting that they do not have a considerable influence on the `LandingOutcome`. The associated density plots also support this observation. We could remove these two `PayloadMass` and `Flights` from the features set.","metadata":{}},{"cell_type":"markdown","source":"#### Group PayloadMass\n\nBased on the informations found on [Wikipedia](https://en.wikipedia.org/wiki/Small-lift_launch_vehicle#See_also), we can group the `PayloadMass` into four groups: Small-Lift (less than 2,000), Medium-Lift (2,000-20,000), Heavy-Lift (20,000-50,000), and Super-Lift (over 50,000).","metadata":{}},{"cell_type":"code","source":"def group_payloadmass(df):\n    df.loc[df[\"PayloadMass\"] < 2000, \"PayloadMass\"] = 0\n    df.loc[(2000 <= df[\"PayloadMass\"]) & (df[\"PayloadMass\"] < 20000), \"PayloadMass\"] = 1\n    df.loc[(20000 <= df[\"PayloadMass\"]) & (df[\"PayloadMass\"] < 50000), \"PayloadMass\"] = 2\n    df.loc[df[\"PayloadMass\"] > 50000, \"PayloadMass\"] = 2\n    df[\"PayloadMass\"].replace({0: \"Light\", 1: \"Medium\", 2: \"Heavy\", 3: \"Super-Heavy\"}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:41.461011Z","iopub.execute_input":"2021-10-19T15:45:41.461243Z","iopub.status.idle":"2021-10-19T15:45:41.466826Z","shell.execute_reply.started":"2021-10-19T15:45:41.461213Z","shell.execute_reply":"2021-10-19T15:45:41.466169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group payload mass\ngroup_payloadmass(df)\n\n# Print success rate per payload group\nprint(round(100 * df.groupby(\"PayloadMass\").mean()[\"LandingOutcome\"], 2))\nprint()\n\n# Show Chi Square p-value matrix against target variable\nplot_chisquare_heatmap(df, column_names=[\"PayloadMass\"], target=\"LandingOutcome\", figsize=(5,3.5))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:41.467867Z","iopub.execute_input":"2021-10-19T15:45:41.468188Z","iopub.status.idle":"2021-10-19T15:45:41.754862Z","shell.execute_reply.started":"2021-10-19T15:45:41.468163Z","shell.execute_reply":"2021-10-19T15:45:41.754298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Even after grouping its values into different categories,`PayloadMass` is still independent from `LandingOutcome`.","metadata":{}},{"cell_type":"code","source":"df.drop(columns=[\"PayloadMass\", \"Flights\", \"Year\"], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:41.755694Z","iopub.execute_input":"2021-10-19T15:45:41.756385Z","iopub.status.idle":"2021-10-19T15:45:41.761493Z","shell.execute_reply.started":"2021-10-19T15:45:41.756354Z","shell.execute_reply":"2021-10-19T15:45:41.76061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Features Set <a class=\"anchor\"  id=\"fs-build-dataset\"></a>\nAt this stage, we are left with 5 variables in our features set. Each of these variables are statistically independent to each other and have a tangible relationship with the target.","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:41.762764Z","iopub.execute_input":"2021-10-19T15:45:41.763088Z","iopub.status.idle":"2021-10-19T15:45:41.775433Z","shell.execute_reply.started":"2021-10-19T15:45:41.763049Z","shell.execute_reply":"2021-10-19T15:45:41.774668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_onehot(df, column):\n    # Apply one-hot encoding\n    df = df.join(pd.get_dummies(df[column], prefix=column))\n    # Drop old variable\n    return df.drop(columns=column)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:41.776848Z","iopub.execute_input":"2021-10-19T15:45:41.777401Z","iopub.status.idle":"2021-10-19T15:45:41.785183Z","shell.execute_reply.started":"2021-10-19T15:45:41.777362Z","shell.execute_reply":"2021-10-19T15:45:41.784336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now proceed at transforming this dataset into a appropriate feature set. First we transform the boolean variables to they contains 0 and 1 instead of True and False","metadata":{}},{"cell_type":"code","source":"df = df.astype({\"Legs\": int})","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:41.786825Z","iopub.execute_input":"2021-10-19T15:45:41.787121Z","iopub.status.idle":"2021-10-19T15:45:41.799304Z","shell.execute_reply.started":"2021-10-19T15:45:41.787085Z","shell.execute_reply":"2021-10-19T15:45:41.798559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Considering that most machine learning algorithms require numeric values, we proceed to transforming our categorical features using a one-hot encoding.","metadata":{}},{"cell_type":"code","source":"df = get_onehot(df, column=[\"Orbit\"])\ndf = get_onehot(df, column=[\"LandingRegion\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:41.800649Z","iopub.execute_input":"2021-10-19T15:45:41.801118Z","iopub.status.idle":"2021-10-19T15:45:41.818866Z","shell.execute_reply.started":"2021-10-19T15:45:41.801079Z","shell.execute_reply":"2021-10-19T15:45:41.818046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:41.820124Z","iopub.execute_input":"2021-10-19T15:45:41.820327Z","iopub.status.idle":"2021-10-19T15:45:41.838057Z","shell.execute_reply.started":"2021-10-19T15:45:41.820302Z","shell.execute_reply":"2021-10-19T15:45:41.836944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our features sets are now ready to be fed to a machine learning model","metadata":{}},{"cell_type":"markdown","source":"# Machine Learning Predictions <a class=\"anchor\"  id=\"ml-predictions\"></a>","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:41.839147Z","iopub.execute_input":"2021-10-19T15:45:41.839367Z","iopub.status.idle":"2021-10-19T15:45:41.843748Z","shell.execute_reply.started":"2021-10-19T15:45:41.839343Z","shell.execute_reply":"2021-10-19T15:45:41.842916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(y=None,y_predict=None, cm=None):\n    if y is not None and y_predict is not None:\n        cm = confusion_matrix(y, y_predict, normalize='all')\n    elif cm is None:\n        raise Exception(\"Either confusion matrix or y and y_hat required\")\n    \n    _, ax = plt.subplots(figsize=(4.5,3.5))\n    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n    ax.set_xlabel('Predicted labels')\n    ax.set_ylabel('True labels')\n    ax.set_title('Confusion Matrix', fontsize=14); \n    ax.xaxis.set_ticklabels(['did not land', 'land']);\n    ax.yaxis.set_ticklabels(['did not land', 'landed'])","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:41.845321Z","iopub.execute_input":"2021-10-19T15:45:41.845851Z","iopub.status.idle":"2021-10-19T15:45:41.856748Z","shell.execute_reply.started":"2021-10-19T15:45:41.845812Z","shell.execute_reply":"2021-10-19T15:45:41.856047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenate features and target sets\ndata = np.column_stack((\n    df[[c for c in df.columns if c != \"LandingOutcome\"]].values, \n    df[\"LandingOutcome\"].values\n))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:41.858192Z","iopub.execute_input":"2021-10-19T15:45:41.858446Z","iopub.status.idle":"2021-10-19T15:45:41.875318Z","shell.execute_reply.started":"2021-10-19T15:45:41.858418Z","shell.execute_reply":"2021-10-19T15:45:41.874182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split dataset into train and test sets\n# X_train, X_test, Y_train, Y_test = train_test_split(data[:, :-1], data[:,-1], test_size=0.2, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:41.876293Z","iopub.execute_input":"2021-10-19T15:45:41.876721Z","iopub.status.idle":"2021-10-19T15:45:41.884902Z","shell.execute_reply.started":"2021-10-19T15:45:41.876683Z","shell.execute_reply":"2021-10-19T15:45:41.884272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree <a class=\"anchor\"  id=\"ml-decision-tree\"></a>\nAs noted earlier, the classes in our data are imbalanced. There are much more successful rocker launches than failures. Decision trees usually perform well on imbalanced data as the splitting rules can force both classes to be addressed.","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:41.885852Z","iopub.execute_input":"2021-10-19T15:45:41.886473Z","iopub.status.idle":"2021-10-19T15:45:41.89946Z","shell.execute_reply.started":"2021-10-19T15:45:41.886443Z","shell.execute_reply":"2021-10-19T15:45:41.898811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parameters = {\n     'criterion': ['gini', 'entropy'],\n     'splitter': ['best', 'random'],\n     'max_depth': [2*n for n in range(1,10)],\n     'max_features': ['auto', 'sqrt'],\n     'min_samples_leaf': [1,2,4],\n     'min_samples_split': [2,3,4,10],\n     'class_weight': ['balanced', None]\n}","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:41.900652Z","iopub.execute_input":"2021-10-19T15:45:41.901234Z","iopub.status.idle":"2021-10-19T15:45:41.912851Z","shell.execute_reply.started":"2021-10-19T15:45:41.901201Z","shell.execute_reply":"2021-10-19T15:45:41.91198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid=parameters, scoring=\"accuracy\", cv=6)\ntree_cv.fit(data[:, :-1], data[:, -1])\ntree_cv.best_score_","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:41.914279Z","iopub.execute_input":"2021-10-19T15:45:41.914761Z","iopub.status.idle":"2021-10-19T15:45:57.933602Z","shell.execute_reply.started":"2021-10-19T15:45:41.91473Z","shell.execute_reply":"2021-10-19T15:45:57.932665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree_cv.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:57.934974Z","iopub.execute_input":"2021-10-19T15:45:57.935211Z","iopub.status.idle":"2021-10-19T15:45:57.941843Z","shell.execute_reply.started":"2021-10-19T15:45:57.935184Z","shell.execute_reply":"2021-10-19T15:45:57.940798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Because we are dealing with a very small dataset that is also imbalanced, it would be a good idea to evaluate our models using a stratified cross validation.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:57.94322Z","iopub.execute_input":"2021-10-19T15:45:57.943626Z","iopub.status.idle":"2021-10-19T15:45:57.953896Z","shell.execute_reply.started":"2021-10-19T15:45:57.943586Z","shell.execute_reply":"2021-10-19T15:45:57.953097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_splits = 10\nn_repeats = 2\n# Matrix of scores: accuracy, precision, recall, and f1\nscores = np.zeros((n_splits * n_repeats, 4))\n# Combines the confusion matrices of each fold\nconfusion_matrices = np.zeros((n_splits * n_repeats, 4))\n\nskfold = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\ni = 0\nfor train_idx, test_idx in skfold.split(data[:,:-1], data[:,-1]):\n    X_train, Y_train = data[train_idx, :-1], data[train_idx, -1]\n    X_test, Y_test = data[test_idx, :-1], data[test_idx, -1]\n    \n    # Train model\n    model = DecisionTreeClassifier(\n        class_weight=None,\n        criterion=\"gini\",\n        max_depth=6,\n        max_features=\"auto\",\n        min_samples_leaf=2,\n        min_samples_split=10,\n        splitter=\"best\",\n        random_state=42\n    )\n    \n    model.fit(X_train, Y_train)\n    \n    # Evaluate predictions\n    predictions = model.predict(X_test)\n    \n    # Record evaluation scores\n    scores[i][0] = accuracy_score(predictions, Y_test)\n    scores[i][1] = precision_score(predictions, Y_test)\n    scores[i][2] = recall_score(predictions, Y_test)\n    scores[i][3] = f1_score(predictions, Y_test)\n    \n    # Build a confusion matrix for each bootstrap iteration\n    cm = confusion_matrix(predictions, Y_test, normalize=\"true\")\n    confusion_matrices[i][0] = cm[0][0]\n    confusion_matrices[i][1] = cm[0][1]\n    confusion_matrices[i][2] = cm[1][0]\n    confusion_matrices[i][3] = cm[1][1]\n    \n    i += 1\n\nscores = np.mean(scores, axis=0)\nprint(\"accuracy: %.2f precision: %.2f recall: %.2f f1: %.2f\" % (scores[0], scores[1], scores[2], scores[3]))","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:57.955377Z","iopub.execute_input":"2021-10-19T15:45:57.955694Z","iopub.status.idle":"2021-10-19T15:45:58.035976Z","shell.execute_reply.started":"2021-10-19T15:45:57.955656Z","shell.execute_reply":"2021-10-19T15:45:58.035103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrices = np.mean(confusion_matrices, axis=0)\ncm = np.reshape(confusion_matrices, (-1, 2))\nplot_confusion_matrix(cm=cm)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T15:45:58.037379Z","iopub.execute_input":"2021-10-19T15:45:58.037855Z","iopub.status.idle":"2021-10-19T15:45:58.284885Z","shell.execute_reply.started":"2021-10-19T15:45:58.037817Z","shell.execute_reply":"2021-10-19T15:45:58.284285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results <a class=\"anchor\"  id=\"ml-results\"></a>","metadata":{}},{"cell_type":"markdown","source":"Our decision tree model is able to reach satisfying performances. We obtain an accuracy of 91%, a precision of 99% and recall of 90%. The F1-score is at 94%. \n\nBased on the above confusion matrix, our model is slightly better at predicting if the first stage will land successfully.","metadata":{}}]}